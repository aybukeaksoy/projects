{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "MOsHUjgdIrIW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8be4c13c-4efb-4758-bca8-21c7dab9269a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.6)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.7.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.13.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.66.6)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.9.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (75.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.4.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.23.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.8.30)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.20.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.16.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Collecting sklearn-crfsuite\n",
            "  Downloading sklearn_crfsuite-0.5.0-py2.py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting python-crfsuite>=0.9.7 (from sklearn-crfsuite)\n",
            "  Downloading python_crfsuite-0.9.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: scikit-learn>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from sklearn-crfsuite) (1.5.2)\n",
            "Requirement already satisfied: tabulate>=0.4.2 in /usr/local/lib/python3.10/dist-packages (from sklearn-crfsuite) (0.9.0)\n",
            "Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.10/dist-packages (from sklearn-crfsuite) (4.66.6)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.0->sklearn-crfsuite) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.0->sklearn-crfsuite) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.0->sklearn-crfsuite) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.0->sklearn-crfsuite) (3.5.0)\n",
            "Downloading sklearn_crfsuite-0.5.0-py2.py3-none-any.whl (10 kB)\n",
            "Downloading python_crfsuite-0.9.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: python-crfsuite, sklearn-crfsuite\n",
            "Successfully installed python-crfsuite-0.9.11 sklearn-crfsuite-0.5.0\n"
          ]
        }
      ],
      "source": [
        "# write the list of necessary packages here:\n",
        "!pip install pandas\n",
        "!pip install nltk\n",
        "!pip install spacy\n",
        "!pip install scikit-learn\n",
        "!pip install sklearn-crfsuite"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rEJBSTyZIrIb"
      },
      "source": [
        "## Training a model on Named Entity Recognition task"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7AGryS1Ugtua"
      },
      "source": [
        "Token classification refers to the task of classifying individual tokens in a sentence. One of the most common token\n",
        "classification tasks is Named Entity Recognition (NER). NER attempts to find a label for each entity in a sentence,\n",
        "such as a person, location, or organization. In this assignment, you will learn how to train a model on the [CoNLL 2023 NER Dataset](https://www.clips.uantwerpen.be/conll2003/ner/) dataset to detect new entities."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whPRbBNbIrIl"
      },
      "source": [
        "### Loading the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "IreSlFmlIrIm"
      },
      "outputs": [],
      "source": [
        "# import your packages here:\n",
        "import pandas as pd\n",
        "import nltk\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Change directory to mdrive\n",
        "os.chdir('/content/drive/MyDrive')\n",
        "\n"
      ],
      "metadata": {
        "id": "-vHmTpj5-Zk3"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "CMAvy1o33OdY",
        "outputId": "c1cc4fdb-2b91-4bfa-fe40-6b65fa95a178",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(204566, 4), (51577, 4), (46665, 4)\n"
          ]
        }
      ],
      "source": [
        "train_df = pd.read_csv(\"ner_data/train.txt\", header=0, sep=\" \")\n",
        "val_df = pd.read_csv(\"ner_data/val.txt\", header=0, sep=\" \")\n",
        "test_df = pd.read_csv(\"ner_data/test.txt\", header=0, sep=\" \")\n",
        "\n",
        "print(f\"{train_df.shape}, {val_df.shape}, {test_df.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmTf7QSV3OdZ"
      },
      "source": [
        "The CoNLL-2003 shared task data files contain four columns separated by a single space. Each word has been put on a separate line and there is an empty line after each sentence. The first item on each line is a word, the second a part-of-speech (POS) tag, the third a syntactic chunk tag and the fourth the named entity tag. The chunk tags and the named entity tags have the format I-TYPE which means that the word is inside a phrase of type TYPE. Only if two phrases of the same type immediately follow each other, the first word of the second phrase will have tag B-TYPE to show that it starts a new phrase. A word with tag O is not part of a phrase. Here is an example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "RJG0_L_B3OdZ",
        "outputId": "f4de448f-965c-46f9-8f5f-06e78253f8cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  -DOCSTART-  -X- -X-.1       O\n",
              "0         EU  NNP  B-NP   B-ORG\n",
              "1    rejects  VBZ  B-VP       O\n",
              "2     German   JJ  B-NP  B-MISC\n",
              "3       call   NN  I-NP       O\n",
              "4         to   TO  B-VP       O\n",
              "5    boycott   VB  I-VP       O\n",
              "6    British   JJ  B-NP  B-MISC\n",
              "7       lamb   NN  I-NP       O\n",
              "8          .    .     O       O\n",
              "9      Peter  NNP  B-NP   B-PER"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-78bbb74f-0878-4756-8ddd-1bb7a32d1787\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>-DOCSTART-</th>\n",
              "      <th>-X-</th>\n",
              "      <th>-X-.1</th>\n",
              "      <th>O</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>EU</td>\n",
              "      <td>NNP</td>\n",
              "      <td>B-NP</td>\n",
              "      <td>B-ORG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>rejects</td>\n",
              "      <td>VBZ</td>\n",
              "      <td>B-VP</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>German</td>\n",
              "      <td>JJ</td>\n",
              "      <td>B-NP</td>\n",
              "      <td>B-MISC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>call</td>\n",
              "      <td>NN</td>\n",
              "      <td>I-NP</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>to</td>\n",
              "      <td>TO</td>\n",
              "      <td>B-VP</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>boycott</td>\n",
              "      <td>VB</td>\n",
              "      <td>I-VP</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>British</td>\n",
              "      <td>JJ</td>\n",
              "      <td>B-NP</td>\n",
              "      <td>B-MISC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>lamb</td>\n",
              "      <td>NN</td>\n",
              "      <td>I-NP</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>.</td>\n",
              "      <td>.</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Peter</td>\n",
              "      <td>NNP</td>\n",
              "      <td>B-NP</td>\n",
              "      <td>B-PER</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-78bbb74f-0878-4756-8ddd-1bb7a32d1787')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-78bbb74f-0878-4756-8ddd-1bb7a32d1787 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-78bbb74f-0878-4756-8ddd-1bb7a32d1787');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-5004eaa5-5479-4480-a494-0c90cebd8dde\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5004eaa5-5479-4480-a494-0c90cebd8dde')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-5004eaa5-5479-4480-a494-0c90cebd8dde button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_df"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "train_df.head(10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "5T0r8VFO3Oda"
      },
      "outputs": [],
      "source": [
        "label_list = ['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC']\n",
        "\n",
        "labels_vocab = {'O': 0, 'B-PER': 1, 'I-PER': 2, 'B-ORG': 3, 'I-ORG': 4, 'B-LOC': 5, 'I-LOC': 6, 'B-MISC': 7, 'I-MISC': 8}\n",
        "labels_vocab_reverse = {v:k for k,v in labels_vocab.items()}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_IaOYX2Z3Odb"
      },
      "source": [
        "### Feature Extraction\n",
        "\n",
        "You need to extract features for each token. The features can be:\n",
        "• Basic features: Token itself, token lowercase, prefix/suffix of the token.\n",
        "• Context features: Neighboring tokens (previous/next token).\n",
        "• Linguistic features: Part-of-speech (POS) tags or word shapes (capitalization, digits,\n",
        "etc.).\n",
        "Note that you are expected to briefly mention which features you employ for training your\n",
        "model."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def separate_sentences(file_path):\n",
        "\n",
        "    with open(file_path, 'r') as file:\n",
        "        lines = file.readlines()\n",
        "\n",
        "    sentences = []\n",
        "    current_sentence = []\n",
        "\n",
        "    for line in lines:\n",
        "        line = line.strip()\n",
        "        if line:\n",
        "            current_sentence.append(line.split(\" \"))\n",
        "        else:\n",
        "            if current_sentence:\n",
        "                sentences.append(current_sentence)\n",
        "                current_sentence = []\n",
        "    if current_sentence:\n",
        "        sentences.append(current_sentence)\n",
        "\n",
        "    return sentences\n",
        "\n",
        "train_file_path = \"ner_data/train.txt\"\n",
        "train_sentences = separate_sentences(train_file_path)\n",
        "\n",
        "test_file_path = \"ner_data/test.txt\"\n",
        "test_sentences = separate_sentences(test_file_path)\n"
      ],
      "metadata": {
        "id": "3tAEa2pK2bBi"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Word features are explained in the reporting part."
      ],
      "metadata": {
        "id": "sXfx93R5SNmx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "nlp.max_length = 1104033\n",
        "\n",
        "def extract_features_from_sentence(sentence):\n",
        "    features = []\n",
        "    labels = []\n",
        "    prev_token = None\n",
        "\n",
        "    for i in range(len(sentence)):\n",
        "\n",
        "        token_text = sentence[i][0]\n",
        "        token = nlp(token_text)[0]\n",
        "\n",
        "        word_features = {\n",
        "            'word': token.text,\n",
        "            'lower': token.text.lower(),\n",
        "            'prefix': token.text[:3],  # Prefix: first 3 characters\n",
        "            'suffix': token.text[-3:],  # Suffix: last 3 characters\n",
        "            'shape': token.shape_,\n",
        "            'is_digit': token.text.isdigit(),\n",
        "            'POS': token.pos_,\n",
        "        }\n",
        "\n",
        "        # Previous token features\n",
        "        if prev_token is None:\n",
        "            word_features.update({\n",
        "                '-1:word': \"\",\n",
        "            })\n",
        "        else:\n",
        "            word_features.update({\n",
        "                '-1:word': prev_token.text,\n",
        "            })\n",
        "\n",
        "        # Next token features\n",
        "        if i + 1 < len(sentence):\n",
        "            next_token_text = sentence[i + 1][0]\n",
        "            next_token = nlp(next_token_text)[0]\n",
        "            word_features.update({\n",
        "                '+1:word': next_token.text,\n",
        "            })\n",
        "        else:\n",
        "            word_features.update({\n",
        "                '+1:word': \"\",\n",
        "            })\n",
        "\n",
        "        features.append(word_features)\n",
        "        labels.append(sentence[i][3])\n",
        "\n",
        "        prev_token = token\n",
        "\n",
        "    return features, labels\n"
      ],
      "metadata": {
        "id": "nD65gm4GG_qx"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = []\n",
        "y = []\n",
        "for sentence in train_sentences:\n",
        "    train_features,train_labels = extract_features_from_sentence(sentence)\n",
        "    X.append(train_features)\n",
        "    y.append(train_labels)"
      ],
      "metadata": {
        "id": "PIC1wVuWpfN8"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fPQpwrjX3Odc"
      },
      "source": [
        "### Train a NER Classifier Model\n",
        "\n",
        "Implement one of the following classifiers for recognizing multiple entity types (e.g., person, organization, location): Conditional Random Field (CRF), biLSTM or multinomial logistic regression. Select only one and provide a brief explanation for\n",
        "your choice of model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "StoVVF3R3Odd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb64367f-279b-4d21-8e07-8bb6fb0c4205"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CRF model training complete!\n"
          ]
        }
      ],
      "source": [
        "# write your code here:\n",
        "from sklearn_crfsuite import CRF\n",
        "\n",
        "crf = CRF(\n",
        "    algorithm='lbfgs',            # Optimization algorithm\n",
        "    c1=0.1,                       # Coefficient for L1 regularization\n",
        "    c2=0.1,                       # Coefficient for L2 regularization\n",
        "    max_iterations=100,           # Maximum number of iterations\n",
        "    all_possible_transitions=True # Allow transitions between all labels\n",
        ")\n",
        "\n",
        "crf.fit(X[1:], y[1:])\n",
        "\n",
        "print(\"CRF model training complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9XZzgqg23Odd"
      },
      "source": [
        "### Evaluation\n",
        "\n",
        "Evaluate the model on the test set using metrics such as precision, recall, and F1-score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "-KbxN4yL3Ode"
      },
      "outputs": [],
      "source": [
        "# write your code here:\n",
        "test_X = []\n",
        "test_y = []\n",
        "for sentence in test_sentences:\n",
        "    test_features, test_labels = extract_features_from_sentence(sentence)\n",
        "    test_X.append(test_features)\n",
        "    test_y.append(test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "rE3MLJtm3Ode"
      },
      "outputs": [],
      "source": [
        "test_y_pred = crf.predict(test_X)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn_crfsuite import metrics\n",
        "\n",
        "classification_report = metrics.flat_classification_report(\n",
        "    test_y, test_y_pred, digits=3\n",
        ")\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report)\n",
        "\n",
        "f1_score = metrics.flat_f1_score(test_y, test_y_pred, average='weighted')\n",
        "precision = metrics.flat_precision_score(test_y, test_y_pred, average='weighted')\n",
        "recall = metrics.flat_recall_score(test_y, test_y_pred, average='weighted')\n",
        "\n",
        "print(f\"Weighted Precision: {precision:.3f}\")\n",
        "print(f\"Weighted Recall: {recall:.3f}\")\n",
        "print(f\"Weighted F1-Score: {f1_score:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46LQaGpoEf5X",
        "outputId": "5fbe0359-b328-4f82-bb22-5d10ebc49fe4"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       B-LOC      0.857     0.883     0.870      1668\n",
            "      B-MISC      0.833     0.775     0.803       702\n",
            "       B-ORG      0.808     0.710     0.756      1661\n",
            "       B-PER      0.831     0.861     0.846      1617\n",
            "       I-LOC      0.769     0.763     0.766       257\n",
            "      I-MISC      0.615     0.681     0.646       216\n",
            "       I-ORG      0.689     0.738     0.713       835\n",
            "       I-PER      0.872     0.964     0.915      1156\n",
            "           O      0.990     0.988     0.989     38554\n",
            "\n",
            "    accuracy                          0.959     46666\n",
            "   macro avg      0.807     0.818     0.811     46666\n",
            "weighted avg      0.959     0.959     0.959     46666\n",
            "\n",
            "Weighted Precision: 0.959\n",
            "Weighted Recall: 0.959\n",
            "Weighted F1-Score: 0.959\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wMqIyJ4Z3Ode"
      },
      "source": [
        "### Reporting\n",
        "\n",
        "Summarize your findings and suggest potential improvements for future iterations of the NER system. Additionally, discuss whether your model encountered class imbalance issues and how you addressed them. Write your suggestions to the given markdown cells."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "INTRODUCTION\n",
        "\n",
        "Named entity recognition (NER) identifies predefined categories of objects in a body of text. This report outlines the development and evaluation of an NER model using the CoNLL 2003 NER Shared Task's English dataset. The objective is to accurately recognize multiple entity types by extracting relevant features and implementing a suitable classification model.\n",
        "\n",
        "FEATURE EXTRACTION\n",
        "\n",
        "Effective feature extraction is crucial for the performance of our NER model. The features used in this task are a combination of basic, contextual, and linguistic characteristics of each token in the text.\n",
        "\n",
        "Basic Features\n",
        "\n",
        "Token Itself: The original word as it appears in the text.\n",
        "Lowercase Token: The token converted to lowercase to normalize case variations.\n",
        "Prefix: The first three characters of the token, capturing common prefixes.\n",
        "Suffix: The last three characters of the token, capturing common suffixes.\n",
        "Shape: The word shape, which encodes patterns of capitalization, numerals, and punctuation (e.g., 'Xxxx' for 'John').\n",
        "\n",
        "Contextual Features\n",
        "\n",
        "Previous Token: The word immediately preceding the current token.\n",
        "Next Token: The word immediately following the current token.\n",
        "\n",
        "Linguistic Features\n",
        "\n",
        "Part-of-Speech (POS) Tag: The grammatical role of the token (e.g., noun, verb), providing syntactic context.\n",
        "Is Digit: A boolean indicating whether the token consists of digits.\n",
        "\n",
        "MODEL IMPLEMENTATION\n",
        "\n",
        "For this task, a Conditional Random Field (CRF) model was implemented for recognition of NER.\n",
        "\n",
        "CRF was chosen for its effectiveness in sequence labeling tasks like NER. Unlike models that make independent predictions for each token, CRF considers the context of the entire sequence, modeling the conditional probability of the label sequence given the input sequence. This allows the model to capture dependencies between neighboring labels, which is essential for correctly identifying multi-token entities and ensuring consistent labeling.\n",
        "\n",
        "The model was trained using the extracted features from the training set. The logistic regression classifier predicts the probability of each token belonging to a particular entity class based on the input features.\n",
        "\n",
        "The model's performance was evaluated on the test set using precision, recall, and F1-score metrics for each entity class. The classification report can be found in the previous part.\n",
        "\n",
        "RESULTS\n",
        "\n",
        "The model achieves high precision and recall for the 'O' class (non-entity tokens), which is expected due to its large representation in the dataset.\n",
        "Entity classes like 'B-LOC' and 'B-PER' have high F1-scores, indicating good performance in recognizing locations and persons.\n",
        "Lower performance is observed for classes like 'I-MISC' and 'I-ORG', suggesting difficulty in correctly identifying multi-token miscellaneous entities and organizations.\n",
        "\n",
        "The model demonstrates strong overall performance with an accuracy of 95.9% and a weighted F1-score of 0.959.\n",
        "The combination of basic, contextual, and linguistic features contributes to the model's ability to distinguish between different entity types.\n",
        "\n",
        "Class Imbalance: A significant imbalance exists between the 'O' class and the entity classes, with the 'O' class comprising the majority of the dataset. The dominance of the 'O' class can bias the model toward predicting non-entity labels, potentially reducing the recall for actual entities.\n",
        "\n",
        "To overcome the problem, in the CRF model, transition probabilities between labels can be adjusted to account for class imbalance. Although challenging due to sequence dependencies, attempts can be made to train on more balanced subsets of the data.\n",
        "\n",
        "POTENTIAL IMPROVEMENTS\n",
        "\n",
        "Enhanced Feature Engineering:\n",
        "\n",
        "To capture morphological patterns within words for improving recognition of rare or out-of-vocabulary words, character n-grams or embeddings can be incorporated. Also, pre-trained word embeddings (e.g., GloVe, Word2Vec) can be utilized to provide semantic context beyond the token level.\n",
        "\n",
        "Integration of neural networks with CRF can be considered to capture non-linear relationships in the data.\n",
        "- Bidirectional LSTM-CRF\n",
        "- Bidirectional Long Short-Term Memory (BiLSTM)\n",
        "\n",
        "Using additional training examples for underrepresented classes can be helpful to balance the dataset.\n",
        "\n",
        "Fine-tuning the L1 and L2 regularization coefficients to prevent overfitting while maintaining model complexity.\n",
        "and experimenting with different feature combinations to identify the most impactful features is essential to optimal hyperparameters and highly affect the model performance. Also, K-fold cross-validation can be used to obtain a more robust estimate of the model's performance.\n",
        "\n",
        "Conclusion\n",
        "The NER model developed in this project successfully identifies various entity types with high accuracy. While the model performs well overall, there is room for improvement, particularly in handling class imbalance and enhancing recognition of less frequent entity types. Future iterations can leverage advanced models and enriched feature sets to achieve better performance."
      ],
      "metadata": {
        "id": "ThWs8nJRGX-_"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gEOKu9tG3Odf"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CXqDQijM3Odf"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}